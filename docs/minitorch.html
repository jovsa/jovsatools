---

title: Minitorch


keywords: fastai
sidebar: home_sidebar

summary: "Building torch from from the ground up!"
description: "Building torch from from the ground up!"
nb_path: "notebooks/minitorch.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: notebooks/minitorch.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note:</p>
<ul>
<li>TODO: imports needs to be fixed for running all pytest for this module. </li>
<li>numba needs a GPU else all tests which test such functionality will fail</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Minitorch">Minitorch<a class="anchor-link" href="#Minitorch"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;Add&#39;,
 &#39;Context&#39;,
 &#39;Conv2dFun&#39;,
 &#39;CudaOps&#39;,
 &#39;CudaTensorFunctions&#39;,
 &#39;Exp&#39;,
 &#39;FastOps&#39;,
 &#39;Function&#39;,
 &#39;FunctionBase&#39;,
 &#39;History&#39;,
 &#39;IndexingError&#39;,
 &#39;Inv&#39;,
 &#39;LT&#39;,
 &#39;Log&#39;,
 &#39;MAX_DIMS&#39;,
 &#39;MatMul&#39;,
 &#39;Max&#39;,
 &#39;Module&#39;,
 &#39;Mul&#39;,
 &#39;Neg&#39;,
 &#39;Parameter&#39;,
 &#39;ReLU&#39;,
 &#39;Scalar&#39;,
 &#39;ScalarFunction&#39;,
 &#39;Sigmoid&#39;,
 &#39;Tensor&#39;,
 &#39;TensorData&#39;,
 &#39;TensorFunctions&#39;,
 &#39;TensorOps&#39;,
 &#39;Variable&#39;,
 &#39;VariableWithDeriv&#39;,
 &#39;__builtins__&#39;,
 &#39;__cached__&#39;,
 &#39;__doc__&#39;,
 &#39;__file__&#39;,
 &#39;__loader__&#39;,
 &#39;__name__&#39;,
 &#39;__package__&#39;,
 &#39;__path__&#39;,
 &#39;__spec__&#39;,
 &#39;argmax&#39;,
 &#39;array&#39;,
 &#39;autodiff&#39;,
 &#39;avgpool2d&#39;,
 &#39;backpropagate&#39;,
 &#39;broadcast_index&#39;,
 &#39;central_difference&#39;,
 &#39;conv2d&#39;,
 &#39;count&#39;,
 &#39;cuda&#39;,
 &#39;cuda_functions&#39;,
 &#39;cuda_matmul&#39;,
 &#39;cuda_ops&#39;,
 &#39;derivative_check&#39;,
 &#39;dropout&#39;,
 &#39;fast_ops&#39;,
 &#39;float64&#39;,
 &#39;functions&#39;,
 &#39;grad_check&#39;,
 &#39;index_to_position&#39;,
 &#39;is_constant&#39;,
 &#39;is_leaf&#39;,
 &#39;logsoftmax&#39;,
 &#39;make_tensor_functions&#39;,
 &#39;map&#39;,
 &#39;matmul&#39;,
 &#39;matrix_multiply&#39;,
 &#39;max&#39;,
 &#39;max_reduce&#39;,
 &#39;maxpool2d&#39;,
 &#39;module&#39;,
 &#39;modules&#39;,
 &#39;ndarray&#39;,
 &#39;njit&#39;,
 &#39;nn&#39;,
 &#39;np&#39;,
 &#39;numba&#39;,
 &#39;numpy&#39;,
 &#39;operators&#39;,
 &#39;prange&#39;,
 &#39;prod&#39;,
 &#39;rand&#39;,
 &#39;random&#39;,
 &#39;reduce&#39;,
 &#39;scalar&#39;,
 &#39;scalar_modules&#39;,
 &#39;shape_broadcast&#39;,
 &#39;softmax&#39;,
 &#39;strides_from_shape&#39;,
 &#39;tensor&#39;,
 &#39;tensor_conv2d&#39;,
 &#39;tensor_data&#39;,
 &#39;tensor_fromlist&#39;,
 &#39;tensor_map&#39;,
 &#39;tensor_ops&#39;,
 &#39;tensor_reduce&#39;,
 &#39;tensor_zip&#39;,
 &#39;tile&#39;,
 &#39;unwrap_tuple&#39;,
 &#39;uuid&#39;,
 &#39;version&#39;,
 &#39;wrap_tuple&#39;,
 &#39;zeros&#39;,
 &#39;zip&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="References">References<a class="anchor-link" href="#References"> </a></h2><ul>
<li><a href="https://minitorch.github.io/">MiniTorch</a></li>
</ul>

</div>
</div>
</div>
</div>
 

