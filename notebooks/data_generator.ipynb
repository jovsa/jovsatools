{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator\n",
    "\n",
    "> Data Generation classes for experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import *\n",
    "import numpy as np\n",
    "import jovsatools\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST multi-target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class MNISTDataGenerator(object):\n",
    "    \"\"\"Generates a multi-calss regression/classification data based on MNIST\n",
    "    \n",
    "        x = mnist data flattened\n",
    "        y = regression/classification targets based on self.initialize()\n",
    "        \n",
    "        Arguments:\n",
    "            additional_y: Integer, used to specify the additional targets\n",
    "            seed = Integer, used to specify np.random.seed()\n",
    "        \n",
    "        Returns: \n",
    "            train_x: numpy.ndarray, MNIST train data flattened\n",
    "            train_y: numpy.ndarray, all the targets; MNIST label + additional_y\n",
    "            test_x: numpy.ndarray, MNIST test data flattened\n",
    "            test_y: numpy.ndarray, all the targets; MNIST label + additional_y\n",
    "    \"\"\"\n",
    "    def __init__(self, additional_y=0, seed=1123):\n",
    "        self.additional_y = additional_y\n",
    "        self.seed = np.random.seed(seed=seed)\n",
    "\n",
    "        # needed to store additional generation functions\n",
    "        self._func_map = {}\n",
    "        self._initialize(additional_y)\n",
    "        \n",
    "        assert list(filter(lambda x: x is None, [\n",
    "            self.mnist_train_x, \n",
    "            self.mnist_train_y, \n",
    "            self.mnist_test_x, \n",
    "            self.mnist_test_y\n",
    "        ])) == []\n",
    "        \n",
    "        self.train_n = len(self.mnist_train_x)\n",
    "        self.test_n = len(self.mnist_test_x)\n",
    "       \n",
    "    def _initialize(self, additional_y):\n",
    "        \"\"\"Prepare functions to approximate \"\"\"\n",
    "        epsilon = 0.000123\n",
    "        C = 102 # emperical value from analyzing MNIST data\n",
    "        \n",
    "        # label 0: mnist class\n",
    "        if additional_y >= 1:\n",
    "            # label 1: classification (0, 1) target\n",
    "            self._func_map[0] = lambda x: int(np.random.random()<0.9) if 2*(x[10]**3)-2*x[3]+15 > 8.9 else 0\n",
    "        \n",
    "        if additional_y >= 2:\n",
    "            # label 2: unbounded regression target\n",
    "            self._func_map[1] = lambda x: np.log(np.sum(x)+epsilon)\n",
    "        \n",
    "        if additional_y >= 3:\n",
    "            # label 3: bounded (0, 1) regression target\n",
    "            self._func_map[2] = lambda x: np.mean(x)/C\n",
    "        \n",
    "        # regular MNIST train/test data\n",
    "        train, test = tf.keras.datasets.mnist.load_data()\n",
    "        self.mnist_train_x, self.mnist_train_y = train[0], train[1]\n",
    "        self.mnist_test_x, self.mnist_test_y = test[0], test[1]\n",
    "    \n",
    "    def prepare_datasets(self, mnist_x, mnist_y, n):\n",
    "        \"\"\"Main worker function for dataset preparation \"\"\"\n",
    "        x, y = [], [] \n",
    "        for i in range(n):\n",
    "            features = mnist_x[i].flatten().reshape(-1, 1)\n",
    "            labels = [mnist_y[i]]\n",
    "            for f in range(self.additional_y):\n",
    "                labels.append(self._func_map[f](features))\n",
    "            x.append(features)\n",
    "            y.append(labels)\n",
    "        return np.asarray(x), np.asarray(y)\n",
    "                \n",
    "    def __call__(self, sample_n):\n",
    "        \"\"\"Data generation call \"\"\"\n",
    "        assert sample_n <= self.train_n, f\"max alloable size is {self.train_n}\"\n",
    "        train_x, train_y = [], []\n",
    "        test_x, test_y = [], []\n",
    "            \n",
    "        train_x, train_y = self.prepare_datasets(self.mnist_train_x, self.mnist_train_y, n=sample_n)\n",
    "        test_x, test_y = self.prepare_datasets(self.mnist_test_x, self.mnist_test_y, n=self.test_n)\n",
    "        return (train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data hyperparms\n",
    "additional_y, train_n = 3, 1000\n",
    "data_generator = MNISTDataGenerator(additional_y)\n",
    "datasets  = data_generator(train_n)\n",
    "train_x, train_y, test_x, test_y = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests\n",
    "\n",
    "#testing if every dataset returned is numpy.ndarray\n",
    "test_eq(\n",
    "    len(\n",
    "        list(\n",
    "            filter(lambda x: 'numpy.ndarray' in x,\n",
    "                   (map(lambda x: str(type(x)), datasets))\n",
    "                  )\n",
    "        )\n",
    "    ), \n",
    "    len(datasets)\n",
    ")\n",
    "test_eq(len(train_y), train_n)\n",
    "test_eq(train_y.shape[1], additional_y+1)\n",
    "test_eq(test_y.shape[1], additional_y+1)\n",
    "\n",
    "# head 0 tests\n",
    "test_eq(list(set(train_y[:, 0])), [i for i in range(0, 10)])\n",
    "test_eq(list(set(test_y[:, 0])), [i for i in range(0, 10)])\n",
    "\n",
    "# head 1 tests\n",
    "test_eq(list(set(train_y[:, 1])), [i for i in range(0, 2)])\n",
    "test_eq(list(set(test_y[:, 1])), [i for i in range(0, 2)])\n",
    "\n",
    "# head 3 tests\n",
    "test_eq(np.min(train_y[:, 3]) >= 0.0, True ) \n",
    "test_eq(np.min(test_y[:, 3]) >= 0.0, True ) \n",
    "test_eq(np.max(train_y[:, 3]) <= 1.0, True ) \n",
    "test_eq(np.max(test_y[:, 3]) <= 1.0, True ) \n",
    "\n",
    "\n",
    "test_eq(len(test_y), 10000) # based on MNIST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('venv-jovsatools': venv)",
   "language": "python",
   "name": "python361064bitvenvjovsatoolsvenv49fafae42f3d4f8ea216fdba9f12778f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
