{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp function_approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Approximation\n",
    "\n",
    "> function approximation playground\n",
    "\n",
    "`Go to Runtime -> Change runtime type and make sure Hardward accelerator is set to GPU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nbdev'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-365e9dec2795>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnbdev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowdoc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjsmltools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nbdev'"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from nbdev.showdoc import *\n",
    "import jsmltools\n",
    "from fastcore.test import *\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "\n",
    "test_eq(tf.__version__, \"2.2.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class DataGenerator(object):\n",
    "    '''generates a multi-calss regression/classification data based on MNIST\n",
    "    \n",
    "        x = mnist data flattened\n",
    "        y = regression/classification targets based on self.initialize()\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, additional_y=0, seed=1123):\n",
    "        self.additional_y = additional_y\n",
    "        self.seed = np.random.seed(seed=seed)\n",
    "        \n",
    "        # needed to store additional generation functions\n",
    "        self._func_map = {}\n",
    "        self._initialize()\n",
    "        \n",
    "        assert list(filter(lambda x: x is None, [\n",
    "            self.mnist_train_x, \n",
    "            self.mnist_train_y, \n",
    "            self.mnist_test_x, \n",
    "            self.mnist_test_y\n",
    "        ])) == []\n",
    "        \n",
    "        self.train_n = len(self.mnist_train_x)\n",
    "        self.test_n = len(self.mnist_test_x)\n",
    "       \n",
    "    def _initialize(self):\n",
    "        '''prepare functions to approximate '''\n",
    "        epsilon = 0.000123\n",
    "        C = 102 # emperical value from analyzing MNIST data\n",
    "        \n",
    "        # classification (0, 1) target\n",
    "        self._func_map[0] = lambda x: int(np.random.random()<0.9) if 2*(x[10]**3)-2*x[3]+15 > 8.9 else 0\n",
    "        \n",
    "        # unbounded regression target\n",
    "        self._func_map[1] = lambda x: np.log(np.sum(x, axis=0)+epsilon)\n",
    "        \n",
    "        # bounded (0, 1) regression target\n",
    "        self._func_map[2] = lambda x: np.mean(x, axis=0)/C\n",
    "        \n",
    "        # regular MNIST train/test data\n",
    "        train, test = tf.keras.datasets.mnist.load_data()\n",
    "        self.mnist_train_x, self.mnist_train_y = train[0], train[1]\n",
    "        self.mnist_test_x, self.mnist_test_y = test[0], test[1]\n",
    "                \n",
    "    def __call__(self, train_n):\n",
    "        '''data generation '''\n",
    "        assert train_n <= self.train_n\n",
    "        train_x, train_y = [], []\n",
    "        test_x, test_y = [], []\n",
    "        \n",
    "        #TODO (jovsa): consolidate the two loop\n",
    "        for i in range(train_n):\n",
    "            x = self.mnist_train_x[i].flatten().reshape(-1, 1)\n",
    "            y = [self.mnist_train_y[i]]\n",
    "            for f in range(self.additional_y):\n",
    "                y.append(self._func_map[f](x))\n",
    "            train_x.append(x)\n",
    "            train_y.append(y)\n",
    "        \n",
    "        # prepating test data\n",
    "        for i in range(self.test_n):\n",
    "            x = self.mnist_test_x[i].flatten().reshape(-1, 1)\n",
    "            y = [self.mnist_test_y[i]]\n",
    "            for f in range(self.additional_y):\n",
    "                y.append(self._func_map[f](x))\n",
    "            test_x.append(x)\n",
    "            test_y.append(y)\n",
    "        \n",
    "        return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating dataset for experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data hyperparms\n",
    "additional_y, train_n = 0, 100\n",
    "data_generator = DataGenerator(additional_y)\n",
    "train_x, train_y, test_x, test_y = data_generator(train_n)\n",
    "\n",
    "# tests\n",
    "test_eq(len(train_y), train_n)\n",
    "test_eq(len(train_y[0]), additional_y+1)\n",
    "test_eq(len(test_y), 10000) # based on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenation\n",
    "\n",
    "Model Based\n",
    "* Using High Level APIs\n",
    "    * tf.keras functional \n",
    "    * tf.keras sklearn wrapper\n",
    "* Custom layers\n",
    "* Custom models\n",
    "* Custom metrics\n",
    "* Custom loss\n",
    "* Custom activation functions\n",
    "* Custom initializers, regularizers and constants\n",
    "* Custom training loops\n",
    "* Custom gradients\n",
    "\n",
    "Data Loading\n",
    " * Tf Example\n",
    " * \n",
    "Hyperparameter Search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using High Level APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore \n",
    "# model = tf.keras.Sequential(\n",
    "#     [\n",
    "#         keras.layers.Dense(16, input_dim=1, activation='relu'),\n",
    "#         keras.layers.Dense(8, activation='relu'),\n",
    "#         keras.layers.Dense(8, activation='relu'),\n",
    "#         keras.layers.Dense(4, activation='relu'),\n",
    "#         keras.layers.Dense(1, activation='relu'),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x=train_x, y=train_y, epochs=200, batch_size=20, verbose=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "* [Keras for Engineers](https://colab.research.google.com/drive/1lWUGZarlbORaHYUZlF9muCgpPl8pEvve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
